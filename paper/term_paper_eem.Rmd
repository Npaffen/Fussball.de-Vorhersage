---
title: '"Stay home" and let the simulation play'
author: 'Nils Paffen, David Schulze'
subtitle: "Predicting the Outcome Kreisliga A Reklinghausen Season 2019-2020"
type: "Working Paper"
discipline: ""
date: "today"
studid: "3071594 (Nils Paffen)"
supervisor: "Prof. Dr. Christoph Hanck"
secondsupervisor: "NA"
estdegree_emester: "Summer Term 2020"
header-includes:
   - \usepackage{dcolumn}
output:
  pdf_document:
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: true
toc: true
lot: true
lof: true
graphics: true
biblio-title: References
fontsize: 12pt
geometry: lmargin = 3 cm,rmargin = 2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references.bib
classoption: a4paper
---


```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
library(knitr)
library(tidyverse)
require(stargazer)
require(kableExtra)
source(here::here("src/functions.R"))
## load data or something for preparation

```
#Maybe add some sport medical data from an actual research papger how 'dangerous' in terms of 'enhanced chances of #infection during football games'. I thought I had heard of something like this but will update the section when
#I find the paper.
#
# Introduction

The Covid-19 epidemic forced sports leagues in Germany to suspend championships that were already in full swing. For example, the Kreisliga Herren Klasse 2 in Recklinghausen finished around 150 games, before the rest were canceled starting from Sunday March 12, 2020, leaving around 90 games left unplayed until the last planned day of the tournament on Sunday May 24, 2020. Given the distinct possibility that there won't be a chance to make up those games later, a burning question for many players and fans is naturally: What if they would have played those games? We attempt to use data on games already played from the website [fussball.de](http://www.fussball.de/spielplan/re-kl-a-2-kreis-recklinghausen-kreisliga-a-herren-saison1920-westfalen/-/staffel/027II28DS800000DVS5489B3VS3GHJJU-G#!/section/matchplan) to answer this question, drawing on established forecasting methods from the literature.


# Literature

Some difficulties with forecasting football matchess like that of e.g. the FIFA World Cup, are not relevant to the Kreisliga. The league system in Germany features two rounds per season. Each club plays each other club twice: Once in each round, and once on each club's home field. This reduces the uncertainty, when compared with the mode of the World Cup. There in the group stage, groups are determined by luck of the draw, a process known as 'seeding'. Groups then play a so called round-robin tournament, also known as all-play-all, were every every group member plays each other, which corresponds to the mode in which the Kreisliga plays. The World Cup then continues with single-elimination, or a knock-out stage, which introduces another even more random path dependencies that are not needed for forecasting the Kreisliga. This implies that part of the existing literature on forecasting results in the FIFA World Cup concerning the group stage is highly relevant for the task at hand, since the game rules are identical.

A natural starting point for forecasting match or season outcomes in football tournaments is using the FIFA points ranking method that is used canonically to evaluate the strength of a team and updated after each game. For example, a recent study by Correa et al. -@correa uses FIFA points to forecast the results of the 2018 FIFA Men's World Cup. This approach has however generated criticism and other methods have been proposed and evaluated. The benchmark study by Laseck et al. -@lasek2013 compares established and proposed rankings. They find that FIFA rankings used to perform slightly worse than alternative methods, especially two versions of the Elo rating system originally proposed by Arpad Elo for the United States Chess Federation to rate competitive chess players. We will consider using the FIFA points method or these two alternative candidates.

The first candidate model is published by the anonymous website EloRatings.net -@eloratings, and is especially adapted for the use in ranking football teams. The second one is the FIFA Women's World Rankings, which has been in use since 2003. It is worth noting that the FIFA Men's World Rankings have been adapted in 2018 to also be based on a modification of the Elo ranking.

The website FuPa.net -@fupa also publishes detailed statistics as well as a so called "Power-Ranking" to evaluate the "Formkurve", a rough measure of very recent performance. Because it is only reflective of very recent games, it is not useful for long term forecasting. Another raw measure would be to calculate the probability of winning by dividing team's current points (victories are 3, draws are 2) by the total of their and their opponent's points, we can call this the "points model".

All these models just use weighted game results or point scores. Another approach would be to use more data, as in Berb√©e et al. -@baseball. While this concerns baseball, the principle is not dependent on the rules of the game, but it is based on the influence of individuals' and team's statistics on game outcomes. This is an application of the model proposed by Albert and Bennet -@albert2007. They use the fact that wins and losses appear to be normally distributed in the long run, so chance and skill should both play a role. Team ability is then calculated as the deviation from the average winning probability over time. Very generally, available statistics are then evaluated to find those that matter the most for team performance, measured in runs per game, which would be goals in football. Those candidate factors are then weighted by regressing them on the team performance. The resulting index is then used to calculate a winning probability and this used then to simulate the season outcome by using weighted coin-flips.

While there is not as much individual player data in football on the level of our analysis, the team average is still something that can be calculated. Also, more information on the games, such as location at home or away, could be candidate factors for performance. For example, one team might benefit more from playing at home than it hurts by being away, receiving a net benefit from location, or the other way around. While these data are certainly interesting, we must be aware of the danger of overfitting the model.

Finally the literature contains references to using betting markets as a benchmark, as they perform relatively well as predictors. For the Kreisliga however, we don't expect betting markets to be deep enough to reach this level of accuracy. Otherwise, they would also be an interesting reference point.


# Data
For the simulation study we decided to use data from the amateur football league of the Kreisliga A Kreis Recklinghausen class A1 in Westphalia, further called Kreisliga A1, for the 2019/2020 season. 16 clubs will play against each other on a total of 30 match days in one home and one away game each. Due to the Covid-19 pandemic, the association has decided to cancel all matches from March 15, 2020. After all, 20 matchdays have already been played until this point in time which corresponds to a database of 158 matches. As the first half of the season had already been completed, each team had already played at least once against each team in the table. The extraction of real data from websites using scraping scripts can be complicated, as website operators have an interest in protecting their data from such automated queries. "Fussball.de" is a website of the DFB (German Football Association) which acts as a collection point for match results and news, especially in the amateur sector.  The match results of the website itself cannot be directly read out. They are masked, so they are made unreadable when viewing the HTML file and are only evaluated afterwards using Javascript and transferred to the CSS of the site.  The site also offers a match report, which graphically represents a temporal course of the match. This is broken down in the HTML code, in contrast to the match results, unmasked, and shows the course of the match in text form. With the help of regular expression operations, the game result can be reconstructed.  The data record was then divided into completed and unplayed games. The latter amount to 89 in this season, which were simulated with the methods in the following chapters.

For further analysis we decided to scrape the data of season 16/17, 17/18 and 18/19 aswell to perform out-of-sample error (OOSE) test statistics.  The latter will indicate the performance of the different methods. 

Give a short overview of the actual standing (ranking table after matchday 20)




# Predictive Models

To predict the outcome of the cancelled games, we calculate the candidate rankings and use them to simulate the end of the 2019/2020 season, usually by way of calculating a winning probability for each missing game. Specifically we calculate

\begin{itemize}
\item the points model,
\item the EloRankings.net model, 
\item a poisson model
\end{itemize}

The first model is just a simple baseline model that calculates the probability of a team A winning a game againsta team B using the formula

\begin{align}
P(A wins) = \frac{table points_A}{{table points}_A + {table points}_B},
\end{align}

where \emph{table points} corresponds to the number of games won at the current state of the season valued at three points plus the number of draws valued at one point. This value also governs the ranking and ultimate placement of the teams in the league. Two questions arise from this approach. Firstly, should the table points be updated after each simulated game? We argue no, because this would not include new information about the relative strength of the teams and just increaes the variance of the result. Secondly, we expect an average over many simulated runs to converge to the initial table when the season was interrupted. This would then defeat the purpose of running a simulaion in the first place, because it does not add any new information, and we could have just used the table as it were. Using this way of simulation is however preferable to an unweighted coin toss, because that would unfairly favor below average teams.

Our second model is based on the rating algorithm from [eloratings.net](eloratings.net/about). The anonymous site operator formulates the rating, representative of the strength of a team, as follows: 

\begin{align}
R_n = R_0 + K \times (W - W_e).
\end{align}

Here, $R_n$ is defined as the new rating as an update of $R_0$, which is the old rating. The weighting factor for each match is defined by the type of tournament in which the match takes place and also controls for friendly matches, which is given to the lowest weight of 20. While matches in world championships and other major international tournaments are given weights between 40 and 60, the rest falls into the category "all other tournaments" which are given a weighting factor of 30. Following this example, we also set K to 30 for matches already played in the Kreisliga A.  The weighting factor K is adjusted again based on the goal difference of the result. Thus, K is increased by $\dfrac{K}{2}$ if the match was won with two goals, by $\dfrac{3}{4}\times K$ if the match was won with three goals and by $\dfrac{3}{4} + \dfrac{(N-3)}{8} \times K$, where N defines the goal difference of the match if the match was won with four or more goals.  W is the result of the match. 0 for a loss, 0.5 for a draw and 1 for a win. $W_e$ is the probability of winning defined by the following formula:

\begin{align}
W_e = 1/(10^{(-dr/400)}+1)
\end{align},

where dr is defined as the rating difference and the home team receives a bonus of 100 points. This bonus is considered to be a psychological advantage resulting from the fact that the game is played in the home stadium(see, e.g., @Pollard2008). 

Our third model uses the poisson distribution to simulate the match result with the probability of a goal in every minute of a match. The probability matrix where the game result is drawn from is a $n \times n$ matrix where each cell indicates the proability of that specific match result. While the rows indicates the goals of the home team, the column indicates the goals of the away team. For example the cell of the first row and in the first column indicates the likelihood that the both teams socre $0$ goals. The poisson probability function of our model can be expressed as:

\begin{align}
P(x) = \dfrac{e^{-\lambda}\lambda^x}{x!}, \lambda > 0
\end{align}

where the lambda represents the average number of goals. First, we estimate the following model from the matches already played:

\begin{align}
goals = home + team + opponent . 
\end{align}

Where goals represents the number of goals scored by a team in a game, home presents a dummy variable that is 1 for the home team and 0 for the away team,it serves to illustrate the home team bonus, team representing the home team, and opponent representing the opponent team.  



```{r , echo=FALSE, results = "asis"}
d <- readr::read_rds(stringr::str_c(here::here() , "data", "database_match_results_1920.rds", sep = "/")) 
d <- 
  bind_rows(
    tibble(
      goals = d$goals_team_home,
      team = d$club_name_home,
      opponent=d$club_name_away,
      home=1),
    tibble(
      goals=d$goals_team_away,
      team=d$club_name_away,
      opponent=d$club_name_home,
      home=0))

# create a fake model
# note that team needs to include all of your factors
fake <- lm(goals ~ home + team , d)
# rename the coefficients
names(fake$coefficients) <- gsub("team","",names(fake$coefficients))


# 
m <- glm(goals ~ home + team +opponent, family=poisson(link=log),data=d)
m.s <- summary(m)

## write a function that fixes the names in the glm output
f <- function(x){
  names(x) <- gsub("team|opponent","", names(x))
  return(x)
}

stargazer(fake,fake,fake,
          # coefficients
          coef = list(
            f( m.s$coefficients[grepl("Intercept|home", rownames(m.s$coefficients)), 1]),
            f( m.s$coefficients[grepl("team", rownames(m.s$coefficients)), 1]),
            f( m.s$coefficients[grepl("opponent", rownames(m.s$coefficients)), 1])
          ),
          # standard errors
          se = list(
            f( m.s$coefficients[grepl("Intercept|home", rownames(m.s$coefficients)), 2]),
            f( m.s$coefficients[grepl("team", rownames(m.s$coefficients)), 2]),
            f( m.s$coefficients[grepl("opponent", rownames(m.s$coefficients)), 2])
          ),
          title  = "Regression ouput of the Poisson Model"  ,
          column.labels = c("control","team", "opponent"),
          colnames = FALSE,
          # calculate pvalue using supplied coeff and se
          t.auto = T,
          #dep.var.caption  = "Dependend variable = goals",
          #out = "stargazer_data.html",
          omit.stat=c("all"),
          type = "latex",
          single.row = TRUE,
          order = c("Constant", "home"),
          align = TRUE,
          column.sep.width = "-30pt",
          font.size = "small",
          style = "aer"
          )
#Template table layout?
```


In summary, the coefficients of the model show that the club "Altendorf-Ulfkotte", both as home and away club, has a strong negative and a strong positive influence???, both highly significant, on goals, i.e. the number of goals. Since the club is in the last place in the current table, as mentioned in the Data section, we expected that
it would be easier to score goals if they played against the team on the last place of the seasons soccer league table rather than the team on the first place. On the other hand it will be harder for this last placed team to score goals even if they are the home team. 


 


Following Correa et al. -@correa, we then run the simulation by drawing the results of each game from a binomial distribution. For each game and team, the probability of winning is dividing the ranking points awarded each team by their and their competitors sum of points.

Running this simulation repeatedly should indicate the distribution and expected average of outcomes. Correa et al. -@correa execute 200,000 runs, but because of the relatively low complexity of the Kreisliga's format compared to the World Cup, especially because there are no eleminiation rounds, we expect to need less repetitions.

A few alternatives have been developed for forecasting football games. The potential of using independent Poisson distributions to match the empirical distribution of goals scored by a team has been improved on by introducing correlation between the teams playing against one another in a bivariate Poisson distribution @karlis2003.

While the independent Poisson distributions already allowed for a better fit and to model the outcome of draws, Boshnakov et al. -@boshnakov2016 used a Weibull count model to improve even on the bivariate Poisson model, allowing them even to outperform betting market in selected bets.


# OOSE Test Statistics

Making predictions of events that might never happen can fairly criticized by a simple question. How do you know that your results reflect reality as good as possible? Following George E. P. Box who is known for his qoute "All models are wrong" which is often extenden by "but some are usefull" we want to show that our models cover the latter. The out-of-sample error test statistic is one way to achieve this. One simply divides a dataset a small test data set and a larger training data set. For the season 16/17, 17/18 and 18/19 we decided to split the dataset at the same point where the COVID-19 pandemic forced the  


# Results
For the simulation study using the elo rating, as explained in the predictive models chapter,we used the average of all matches played in the current season resulting in a tie for the probability of a draw. Half of the percentage points are deducted from the home team's winning probability and half from the away team's winning probability. Then we draw from these three probabilities the game result, team home wins, team away wins or draw. We repeat this procedure for all games and evaluate the results with 3 points for the winning team, 1 point for both teams in case of a draw and 0 points for the losing team. 

In the poissonmodel we calculate for each match the goal probabilities of both teams as a probability matrix based on the model estimation as described in predictive models part. 

All simulations were repeated until the rate of change of the point average was 1% or less. Aggregation to this point occurred after about 2580 for the elo model and after about 1980 for the poisson model. 






```{r echo=FALSE, results = "asis"}
sim_output_elo <- readRDS(paste0(getwd(), "/data/elo_ties_simulation.rds"))




# 2. evaluate result

all_final_tables_elo <- sim_output_elo$all_final_tables %>% rename(score = points)
all_final_tables_elo <- add_run_rank_col(x = all_final_tables_elo)
all_avg_tables_elo <- sim_output_elo$all_avg_tables
all_avg_tables_elo <- add_run_rank_col(x = all_avg_tables_elo)

# average table result
average_table_elo <- all_avg_tables_elo[
  (nrow(all_avg_tables_elo)-15):nrow(all_avg_tables_elo),] 
average_table_elo <- average_table_elo %>% arrange(rank) %>% select(rank, everything(), -run) %>% rename(club_name_elo = club_name, score_elo = score)
```

```{r echo=FALSE}
sim_output_point <- readRDS(paste0(getwd(), "/data/point_simulation.rds"))
# 2. evaluate result
all_final_tables_point <- sim_output_point$all_final_tables
all_final_tables_point <- add_run_rank_col(x = all_final_tables_point)
all_avg_tables_point <- sim_output_point$all_avg_tables
all_avg_tables_point <- add_run_rank_col(x = all_avg_tables_point)

# average table result
average_table_point <- all_avg_tables_point[
  (nrow(all_avg_tables_point)-15):nrow(all_avg_tables_point),] 
 

average_table_point <- average_table_point %>% arrange(rank) %>% select(rank, club_name, score)%>% rename(club_name_points = club_name, score_points = score)
```



```{r echo=FALSE}
sim_output_poisson <- readRDS(paste0(getwd(), "/data/poisson_score_simulation.rds"))

# 2. evaluate result

all_final_tables_poisson <- sim_output_poisson$all_final_tables %>% rename(score = points)
all_final_tables_poisson <- add_run_rank_col(x = all_final_tables_poisson)
all_avg_tables_poisson <- sim_output_poisson$all_avg_tables%>%  rename(score = points, club_name = Group.1 )
all_avg_tables_poisson <- add_run_rank_col(x = all_avg_tables_poisson)

# average table result
average_table_poisson <- all_avg_tables_poisson[
  (nrow(all_avg_tables_poisson)-15):nrow(all_avg_tables_poisson),] 
 

average_table_poisson <- average_table_poisson %>% arrange(rank) %>% select(rank, everything(), -run)%>% rename(club_name_poisson = club_name, score_poisson = score)
all_results <- inner_join(average_table_poisson,average_table_elo, by = "rank") %>%
        inner_join(average_table_point, by = "rank")
kable(all_results,
      caption = "Simulated Final Score Table"
                    ) %>%
  add_header_above(c(" " = 1, "Poisson Distribution Model" = 2, "Elo Rating Model" = 2, "Points Model" = 2 )) %>%
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"),full_width = F)

  

```




# Conclusion
The decision to quit all games later than 08th of march because of the pandemic was not revised while the infection rates relaxed during may and june in Germany. Combined with the unforseeble future of the COVID-19 situation we see a more fair and balanced decision making process by integrating statistical learning techniques, such as those, shown in this paper.

\newpage

\printbibliography




