---
title: 'Stay home and let the simulation play'
author: 'Nils Paffen, David Schulze'
subtitle: "Predicting Kreisliga football league outcomes with statistical simulations "
type: "Working Paper"
discipline: ""
date: "today"
studid: "3071594 (Nils Paffen)"
supervisor: "Prof. Dr. Christoph Hanck"
secondsupervisor: "NA"
estdegree_emester: "Summer Term 2020"
header-includes:
   - \usepackage{dcolumn}
output:
  pdf_document:
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: true
toc: true
lot: true
lof: true
graphics: true
biblio-title: References
fontsize: 12pt
geometry: lmargin = 3 cm,rmargin = 2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references.bib
classoption: a4paper
---


```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
library(knitr)
library(tidyverse)
require(stargazer)
require(kableExtra)
source(here::here("src/functions.R"))
## load data or something for preparation

```



# Abstract

Publicly available data and a high public interest are contributing to the relevance and interest in forecasting football game results. We provide a short overview of the state of the literature and use data from the aborted Kreisliga A Recklinghausen season 2019-20 to predict the season’s outcome using three different statistical approaches. A measure of each team’s strength is calculated from past plays and used as weight in the simulation. For the football league’s organizers, using a prediction algorithm to find a season outcome might be fairer than either annulling the games played thus far or using the table as of now. Research has shown, that measures like the Elo rating system are better predictors of teams’ performance than for example league table points on their own. For this example, we find that gains from using advanced methods are marginal when evaluating them with past seasons’ data.



# Introduction

The Covid-19 epidemic forced sports leagues in Germany to suspend championships that were already in full swing. For example, the Kreisliga Herren Klasse 2 in Recklinghausen finished around 150 games, before the rest were canceled starting from Sunday March12, 2020, leaving around 90 games left unplayed until the last planned day of the tournament on Sunday May 24, 2020. Given that there probably won’t be a chance to make up those games later, a burning question for many players and fans is naturally: What if they would have played those games? We attempt to use data on games already played from the website [fussball.de](http://www.fussball.de/spielplan/re-kl-a-2-kreis-recklinghausen-kreisliga-a-herren-saison1920-westfalen/-/staffel/027II28DS800000DVS5489B3VS3GHJJU-G#!/section/matchplan) to answer this question, drawing on established forecasting methods from the literature.

The league system in Germany features two rounds per season. Each club plays each other club twice: Once in each round, and once on each club’s home field. This means it’s easier to forecast when compared with the mode of tournaments the World Cup. There in the group stage, groups are determined by luck of the draw, a process known as “seeding”. Groups then play a so-called round-robin tournament, also known as all-play-all, were all group members play against each other, which corresponds to the mode in which the Kreisliga plays in each round. But the World Cup then continues with single-elimination, or a knock-out stage, which introduces even more random path dependencies that are not needed for forecasting the Kreisliga. This implies that the part of the existing literature on forecasting results in the FIFA World Cup concerning the group stage remains highly relevant for the task at hand, since the game rules are otherwise identical.

In the next part, we give an overview of models used and evaluated for the purpose of predicting football match outcomes. We introduce a small subset of models more in depth the third part. The fourth part contains the results from calculating a simulation based on these for the Kreisliga A Recklinghausen Herren Klasse 2. We also present some comparative statistics of the model performance and draw some conclusions in the last segment.



# Literature

A natural starting point for forecasting match or season outcomes in football tournaments is using the FIFA points ranking method that is widely used to evaluate the strength of a team and updated after each game. For example, a recent study by Correa et al. -@correa uses FIFA points to forecast the results of the 2018 FIFA Men's World Cup. This approach has however generated criticism @mchale2007, especially that it does not include new information fast enough, and other methods have been proposed and evaluated. The benchmark study by Lasek et al. -@lasek2013 compares established and proposed rankings. They find that FIFA rankings perform slightly worse than alternative methods, especially a version of the Elo rating system originally proposed by Arpad Elo for the United States Chess Federation to rate competitive chess players that was adapted for football championships by the authors of the website EloRatings.net -@eloratings. 

Other studies show the effective prediction power of FIFA rankings, e.g. @suzuki2008. Leitner et al. -@leitner2010 find that bookmakers odds are more predictive than FIFA rankings. In our case we don’t expect betting markets to be deep enough to make this a feasible approach, although it would be an interesting reference point. We do however adopt their use of Spearman’s rank correlation between simulated and real final tournament rankings to evaluate models’ performance and complement it with Kendall’s tau. Lasek et al. -@lasek2013 evaluate using rating points, which are less relevant for our use case than the absolute rankings, which determine whether a team advances, stays or drops out of a league.

We consider three models for our calculation: First, a benchmark model based on the table points of each team at the time when the league was aborted. Second, an Elo rating system, and third a simple model based on the Poisson distribution.

The benchmark model calculates the probability of winning a match by dividing a team's current points (victories are 3, draws are 2) by the total of their and their opponent's points, we can call this the "points model". This model does not include the possibility of a draw. The probability is not updated with after each simulated game, because this does not generate new information about a team’s strength. 

The second model is based on a version of the Elo rating system published anonymously on the website EloRatings.net -@eloratings. The algorithm was originally developed for ranking chess-players. As an “earned” rating system @lasek2013 a team’s rating is iteratively updated according to the outcome of single matches and depending on the expected outcome with regard to the opponent’s rating. This version was especially adapted for the use in ranking football teams. Glickman -@glickman1995 offers a comprehensive discussion of the Elo rating system. 

The third model is a very simple implementation of a Poisson distribution that approximates a probability distribution of goals in each game with a fixed parameter to adjust for the home advantage. This approach follows the literature influenced by @maher1982 and others. Generally, these models include different parameters to allow for team-specific strengths when playing home or away, and while defending or attacking. Parameters for e.g. random effects can be added, which we omit here for simplicity. For a general discussion see @karlis2003. Many extensions of this model as well as model selection algorithms are possible.

For a more recent review of advances in the literature and a new approach based on the Weinbull distribution we refer to @boshnakov2017. They use an evaluation based on calibration curves as well as the payoff from betting strategies and find that their model improves on previous models. 



# Data

For the simulation study we decided to use data from the amateur football league of the Kreisliga A Kreis Recklinghausen class A1 in Westphalia, further called Kreisliga A1, for the 2019/2020 season. 16 clubs will play against each other on a total of 30 match days in one home and one away game each. Due to the Covid-19 pandemic, the association has decided to cancel all matches from March 15, 2020. After all, 20 matchdays have already been played until this point in time which corresponds to a database of 158 matches. As the first half of the season had already been completed, each team had already played at least once against each team in the table. The extraction of real data from websites using scraping scripts can be complicated, as website operators have an interest in protecting their data from such automated queries. "Fussball.de" is a website of the DFB (German Football Association) which acts as a collection point for match results and news, especially in the amateur sector.  The match results of the website itself cannot be directly read out. They are masked, so they are made unreadable when viewing the HTML file and are only evaluated afterwards using Javascript and transferred to the CSS of the site.  The site also offers a match report, which graphically represents a temporal course of the match. This is broken down in the HTML code, in contrast to the match results, unmasked, and shows the course of the match in text form. With the help of regular expression operations, the game result can be reconstructed.  The data record was then divided into completed and unplayed games. The latter amount to 89 in this season, which were simulated with the methods in the following chapters.

For further analysis we decided to scrape the data of season 16/17, 17/18 and 18/19 aswell to perform out-of-sample error (OOSE) test statistics.  The latter will indicate the performance of the different methods. 

Give a short overview of the actual standing (ranking table after matchday 20)



# Predictive Models

To predict the outcome of the cancelled games, we calculate the candidate rankings and use them to simulate the end of the 2019/2020 season, usually by way of calculating a winning probability for each missing game. Specifically we calculate

\begin{itemize}
\item the points model,
\item the EloRankings.net model, 
\item a poisson model
\end{itemize}

The first model is just a simple baseline model that calculates the probability of a team A winning a game againsta team B using the formula

\begin{align}
P(A wins) = \frac{table points_A}{{table points}_A + {table points}_B},
\end{align}

where \emph{table points} corresponds to the number of games won at the current state of the season valued at three points plus the number of draws valued at one point. This value also governs the ranking and ultimate placement of the teams in the league. Two questions arise from this approach. Firstly, should the table points be updated after each simulated game? We argue no, because this would not include new information about the relative strength of the teams and just increaes the variance of the result. Secondly, we expect an average over many simulated runs to converge to the initial table when the season was interrupted. This would then defeat the purpose of running a simulaion in the first place, because it does not add any new information, and we could have just used the table as it were. Using this way of simulation is however preferable to an unweighted coin toss, because that would unfairly favor below average teams.

Our second model is based on the rating algorithm from [eloratings.net](eloratings.net/about). The anonymous site operator formulates the rating, representative of the strength of a team, as follows: 

\begin{align}
R_n = R_0 + K \times (W - W_e).
\end{align}

Here, $R_n$ is defined as the new rating as an update of $R_0$, which is the old rating. The weighting factor for each match is defined by the type of tournament in which the match takes place and also controls for friendly matches, which is given to the lowest weight of 20. While matches in world championships and other major international tournaments are given weights between 40 and 60, the rest falls into the category "all other tournaments" which are given a weighting factor of 30. Following this example, we also set K to 30 for matches already played in the Kreisliga A.  The weighting factor K is adjusted again based on the goal difference of the result. Thus, K is increased by $\dfrac{K}{2}$ if the match was won with two goals, by $\dfrac{3}{4}\times K$ if the match was won with three goals and by $\dfrac{3}{4} + \dfrac{(N-3)}{8} \times K$, where N defines the goal difference of the match if the match was won with four or more goals.  W is the result of the match. 0 for a loss, 0.5 for a draw and 1 for a win. $W_e$ is the probability of winning defined by the following formula:

\begin{align}
W_e = 1/(10^{(-dr/400)}+1)
\end{align},

where dr is defined as the rating difference and the home team receives a bonus of 100 points. This bonus is considered to be a psychological advantage resulting from the fact that the game is played in the home stadium(see, e.g., @Pollard2008). 

Our third model uses the poisson distribution to simulate the match result with the probability of a goal in every minute of a match. The probability matrix where the game result is drawn from is a $n \times n$ matrix where each cell indicates the proability of that specific match result. While the rows indicates the goals of the home team, the column indicates the goals of the away team. For example the cell of the first row and in the first column indicates the likelihood that the both teams socre $0$ goals. The poisson probability function of our model can be expressed as:

\begin{align}
P(x) = \dfrac{e^{-\lambda}\lambda^x}{x!}, \lambda > 0
\end{align}

where the lambda represents the average number of goals. First, we estimate the following model from the matches already played:

\begin{align}
goals = home + team + opponent . 
\end{align}

Where goals represents the number of goals scored by a team in a game, home presents a dummy variable that is 1 for the home team and 0 for the away team,it serves to illustrate the home team bonus, team representing the home team, and opponent representing the opponent team.  



```{r , echo=FALSE, results = "asis"}
d <- readr::read_rds(stringr::str_c(here::here() , "data", "database_match_results_1920.rds", sep = "/")) 
d <- 
  bind_rows(
    tibble(
      goals = d$goals_team_home,
      team = d$club_name_home,
      opponent=d$club_name_away,
      home=1),
    tibble(
      goals=d$goals_team_away,
      team=d$club_name_away,
      opponent=d$club_name_home,
      home=0))

# create a fake model
# note that team needs to include all of your factors
fake <- lm(goals ~ home + team , d)
# rename the coefficients
names(fake$coefficients) <- gsub("team","",names(fake$coefficients))


# 
m <- glm(goals ~ home + team +opponent, family=poisson(link=log),data=d)
m.s <- summary(m)

## write a function that fixes the names in the glm output
f <- function(x){
  names(x) <- gsub("team|opponent","", names(x))
  return(x)
}

stargazer(fake,fake,fake,
          # coefficients
          coef = list(
            f( m.s$coefficients[grepl("Intercept|home", rownames(m.s$coefficients)), 1]),
            f( m.s$coefficients[grepl("team", rownames(m.s$coefficients)), 1]),
            f( m.s$coefficients[grepl("opponent", rownames(m.s$coefficients)), 1])
          ),
          # standard errors
          se = list(
            f( m.s$coefficients[grepl("Intercept|home", rownames(m.s$coefficients)), 2]),
            f( m.s$coefficients[grepl("team", rownames(m.s$coefficients)), 2]),
            f( m.s$coefficients[grepl("opponent", rownames(m.s$coefficients)), 2])
          ),
          title  = "Regression ouput of the Poisson Model"  ,
          column.labels = c("control","team", "opponent"),
          colnames = FALSE,
          # calculate pvalue using supplied coeff and se
          t.auto = T,
          #dep.var.caption  = "Dependend variable = goals",
          #out = "stargazer_data.html",
          omit.stat=c("all"),
          type = "latex",
          single.row = TRUE,
          order = c("Constant", "home"),
          align = TRUE,
          column.sep.width = "-30pt",
          font.size = "small",
          style = "aer"
          )
#Template table layout?
```


In summary, the coefficients of the model show that the club "Altendorf-Ulfkotte", both as home and away club, has a strong negative and a strong positive influence???, both highly significant, on goals, i.e. the number of goals. Since the club is in the last place in the current table, as mentioned in the Data section, we expected that
it would be easier to score goals if they played against the team on the last place of the seasons soccer league table rather than the team on the first place. On the other hand it will be harder for this last placed team to score goals even if they are the home team. 

Following Correa et al. -@correa, we then run the simulation by drawing the results of each game from a binomial distribution. For each game and team, the probability of winning is dividing the ranking points awarded each team by their and their competitors sum of points.

Running this simulation repeatedly should indicate the distribution and expected average of outcomes. Correa et al. -@correa execute 200,000 runs, but because of the relatively low complexity of the Kreisliga's format compared to the World Cup, especially because there are no eleminiation rounds, we expect to need less repetitions.

A few alternatives have been developed for forecasting football games. The potential of using independent Poisson distributions to match the empirical distribution of goals scored by a team has been improved on by introducing correlation between the teams playing against one another in a bivariate Poisson distribution @karlis2003.

While the independent Poisson distributions already allowed for a better fit and to model the outcome of draws, Boshnakov et al. -@boshnakov2016 used a Weibull count model to improve even on the bivariate Poisson model, allowing them even to outperform betting market in selected bets.



# Results

For the simulation study using the elo rating, as explained in the predictive models chapter,we used the average of all matches played in the current season resulting in a tie for the probability of a draw. Half of the percentage points are deducted from the home team's winning probability and half from the away team's winning probability. Then we draw from these three probabilities the game result, team home wins, team away wins or draw. We repeat this procedure for all games and evaluate the results with 3 points for the winning team, 1 point for both teams in case of a draw and 0 points for the losing team. 

In the poissonmodel we calculate for each match the goal probabilities of both teams as a probability matrix based on the model estimation as described in predictive models part. 

All simulations were repeated until the rate of change of the point average was 1% or less. Aggregation to this point occurred after about 2580 for the elo model and after about 1980 for the poisson model. 



```{r echo=FALSE, results = "asis"}
sim_output_elo <- readRDS(paste0(getwd(), "/data/elo_ties_simulation.rds"))




# 2. evaluate result

all_final_tables_elo <- sim_output_elo$all_final_tables %>% rename(score = points)
all_final_tables_elo <- add_run_rank_col(x = all_final_tables_elo)
all_avg_tables_elo <- sim_output_elo$all_avg_tables
all_avg_tables_elo <- add_run_rank_col(x = all_avg_tables_elo)

# average table result
average_table_elo <- all_avg_tables_elo[
  (nrow(all_avg_tables_elo)-15):nrow(all_avg_tables_elo),] 
average_table_elo <- average_table_elo %>% arrange(rank) %>% select(rank, everything(), -run) %>% rename(club_name_elo = club_name, score_elo = score)
```

```{r echo=FALSE}
sim_output_point <- readRDS(paste0(getwd(), "/data/point_simulation.rds"))
# 2. evaluate result
all_final_tables_point <- sim_output_point$all_final_tables
all_final_tables_point <- add_run_rank_col(x = all_final_tables_point)
all_avg_tables_point <- sim_output_point$all_avg_tables
all_avg_tables_point <- add_run_rank_col(x = all_avg_tables_point)

# average table result
average_table_point <- all_avg_tables_point[
  (nrow(all_avg_tables_point)-15):nrow(all_avg_tables_point),] 
 

average_table_point <- average_table_point %>% arrange(rank) %>% select(rank, club_name, score)%>% rename(club_name_points = club_name, score_points = score)
```



```{r echo=FALSE}
sim_output_poisson <- readRDS(paste0(getwd(), "/data/poisson_score_simulation.rds"))

# 2. evaluate result

all_final_tables_poisson <- sim_output_poisson$all_final_tables %>% rename(score = points)
all_final_tables_poisson <- add_run_rank_col(x = all_final_tables_poisson)
all_avg_tables_poisson <- sim_output_poisson$all_avg_tables%>%  rename(score = points, club_name = Group.1 )
all_avg_tables_poisson <- add_run_rank_col(x = all_avg_tables_poisson)

# average table result
average_table_poisson <- all_avg_tables_poisson[
  (nrow(all_avg_tables_poisson)-15):nrow(all_avg_tables_poisson),] 
 

average_table_poisson <- average_table_poisson %>% arrange(rank) %>% select(rank, everything(), -run)%>% rename(club_name_poisson = club_name, score_poisson = score)
all_results <- inner_join(average_table_poisson,average_table_elo, by = "rank") %>%
        inner_join(average_table_point, by = "rank")
kable(all_results,
      caption = "Simulated Final Score Table"
                    ) %>%
  add_header_above(c(" " = 1, "Poisson Distribution Model" = 2, "Elo Rating Model" = 2, "Points Model" = 2 )) %>%
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"),full_width = F)

  

```



# OOSE Test Statistics

Making predictions of events that might never happen can fairly criticized by a simple question. How do you know that your results reflect reality as good as possible? Following George E. P. Box who is known for his qoute "All models are wrong" which is often extenden by "but some are usefull" we want to show that our models cover the latter. The out-of-sample error test statistic is one way to achieve this. One simply divides a dataset a small test data set and a larger training data set. For the season 16/17, 17/18 and 18/19 we decided to split the dataset at the same point where the COVID-19 pandemic forced the  

Following @leitner2010, we evaluate the models’ performance using the rank correlation between their predicted and the real ranking tables for the three past years’ seasons (2016, 2017 and 2018). To increase the relevance for our use case, we use as much training data as was available for this year’s aborted season (2019-20). We find that the Elo ranking system improves on the baseline model, which in turn performs better than the simple Poisson model. The fact that the points model achieves a 1.00 correlation in the 2017-18 season however makes these results doubtful, since the points model converges to the table as it was a the point of interruption. A perfect correlation with the final table can thus only occur if there is no change in the ranking after that date.

Generally, the high correlation between the predicted and the actual table outcomes leads us to believe that adopting the results from each method would provide a fair improvement over anulling the 2019-20 season.

\input{rank_corr.tex}

\input{append_rank_corr.tex}



# Conclusion
The decision to quit all games later than 08th of march because of the pandemic was not revised while the infection rates relaxed during may and june in Germany. Combined with the unforseeble future of the COVID-19 situation we see a more fair and balanced decision making process by integrating statistical learning techniques, such as those, shown in this paper.


TO DO:

-calculate draw in poisson from diagonal?
-add caveats: what other factors play a role, what alternative models are there? use sources
-goal distribution?

\newpage

\printbibliography




